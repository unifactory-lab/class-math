# V. Les Applications Linéaires

Après avoir étudié les espaces vectoriels, nous allons maintenant introduire les **applications linéaires**, qui sont des fonctions préservant la structure vectorielle entre deux espaces vectoriels. Les applications linéaires sont fondamentales en algèbre linéaire car elles permettent de modéliser et d'analyser les transformations entre espaces vectoriels, ce qui a de nombreuses applications en mathématiques, en physique, en ingénierie et en informatique.

## 1. Définition des Applications Linéaires

Soient \( V \) et \( W \) deux espaces vectoriels sur un même corps \( \mathbb{K} \). Une **application linéaire** (ou **transformation linéaire**) est une fonction \( f : V \rightarrow W \) qui satisfait les deux propriétés suivantes pour tous vecteurs \( \vec{u}, \vec{v} \in V \) et pour tout scalaire \( \alpha \in \mathbb{K} \):

1. **Additivité** (ou **linéarité de l'addition**) :

   \[
   f(\vec{u} + \vec{v}) = f(\vec{u}) + f(\vec{v})
   \]

2. **Homogénéité** (ou **linéarité par rapport au scalaire**) :

   \[
   f(\alpha \vec{u}) = \alpha f(\vec{u})
   \]

Ces deux propriétés peuvent être combinées en une seule :

- Pour tous \( \vec{u}, \vec{v} \in V \) et tous \( \alpha, \beta \in \mathbb{K} \) :

  \[
  f(\alpha \vec{u} + \beta \vec{v}) = \alpha f(\vec{u}) + \beta f(\vec{v})
  \]

**Remarque** : Une application linéaire préserve la structure d'espace vectoriel, c'est-à-dire qu'elle transforme les combinaisons linéaires dans \( V \) en combinaisons linéaires correspondantes dans \( W \).

## 2. Exemples d'Applications Linéaires

### 2.1 Multiplication par une Matrice

Soit \( A \in \mathcal{M}_{m,n}(\mathbb{K}) \) une matrice de taille \( m \times n \). L'application \( f : \mathbb{K}^n \rightarrow \mathbb{K}^m \) définie par :

\[
f(\vec{x}) = A\vec{x}
\]

est une application linéaire.

**Preuve** :

- **Additivité** :

  \[
  f(\vec{x} + \vec{y}) = A(\vec{x} + \vec{y}) = A\vec{x} + A\vec{y} = f(\vec{x}) + f(\vec{y})
  \]

- **Homogénéité** :

  \[
  f(\alpha \vec{x}) = A(\alpha \vec{x}) = \alpha A\vec{x} = \alpha f(\vec{x})
  \]

### 2.2 Dérivation

Considérons l'espace vectoriel \( C^\infty(\mathbb{R}, \mathbb{R}) \) des fonctions infiniment différentiables de \( \mathbb{R} \) dans \( \mathbb{R} \). L'application \( D : C^\infty(\mathbb{R}, \mathbb{R}) \rightarrow C^\infty(\mathbb{R}, \mathbb{R}) \) définie par :

\[
D(f) = f'
\]

est une application linéaire.

**Preuve** :

- **Additivité** :

  \[
  D(f + g) = (f + g)' = f' + g' = D(f) + D(g)
  \]

- **Homogénéité** :

  \[
  D(\alpha f) = (\alpha f)' = \alpha f' = \alpha D(f)
  \]

### 2.3 Intégrale Définie

Soit \( V = C([a, b], \mathbb{K}) \), l'espace des fonctions continues sur \( [a, b] \). L'application \( I : V \rightarrow \mathbb{K} \) définie par :

\[
I(f) = \int_a^b f(x) \, dx
\]

est une application linéaire.

**Preuve** :

- **Additivité** :

  \[
  I(f + g) = \int_a^b (f(x) + g(x)) \, dx = \int_a^b f(x) \, dx + \int_a^b g(x) \, dx = I(f) + I(g)
  \]

- **Homogénéité** :

  \[
  I(\alpha f) = \int_a^b \alpha f(x) \, dx = \alpha \int_a^b f(x) \, dx = \alpha I(f)
  \]

## 3. Noyau et Image d'une Application Linéaire

### 3.1 Noyau (\( \ker(f) \))

Le **noyau** d'une application linéaire \( f : V \rightarrow W \) est l'ensemble des vecteurs de \( V \) qui sont envoyés sur le vecteur nul de \( W \) :

\[
\ker(f) = \{ \vec{v} \in V \ | \ f(\vec{v}) = \vec{0}_W \}
\]

**Propriété** : Le noyau de \( f \) est un sous-espace vectoriel de \( V \).

### 3.2 Image (\( \text{Im}(f) \))

L'**image** d'une application linéaire \( f : V \rightarrow W \) est l'ensemble des vecteurs de \( W \) qui sont des images de vecteurs de \( V \) :

\[
\text{Im}(f) = \{ f(\vec{v}) \ | \ \vec{v} \in V \}
\]

**Propriété** : L'image de \( f \) est un sous-espace vectoriel de \( W \).

### 3.3 Exemple

Considérons l'application linéaire \( f : \mathbb{R}^3 \rightarrow \mathbb{R}^2 \) définie par :

\[
f(x, y, z) = (x + y, y + z)
\]

- **Noyau** :

  Résolvons \( f(x, y, z) = (0, 0) \) :

  \[
  \begin{cases}
  x + y = 0 \\
  y + z = 0
  \end{cases}
  \]

  Donc \( x = -y \) et \( z = -y \). Ainsi, le noyau est :

  \[
  \ker(f) = \{ (-y, y, -y) \ | \ y \in \mathbb{R} \}
  \]

- **Image** :

  Puisque pour tout \( (u, v) \in \mathbb{R}^2 \), il existe \( (x, y, z) \in \mathbb{R}^3 \) tel que \( f(x, y, z) = (u, v) \), l'image est tout \( \mathbb{R}^2 \) :

  \[
  \text{Im}(f) = \mathbb{R}^2
  \]

## 4. Matrice d'une Application Linéaire

### 4.1 Représentation Matricielle

Soient \( V \) et \( W \) des espaces vectoriels de dimensions finies, avec \( \dim(V) = n \) et \( \dim(W) = m \). Soient \( \{ \vec{e}_1, \dots, \vec{e}_n \} \) une base de \( V \) et \( \{ \vec{f}_1, \dots, \vec{f}_m \} \) une base de \( W \). Une application linéaire \( f : V \rightarrow W \) est entièrement déterminée par les images des vecteurs de la base de \( V \).

La matrice \( A \in \mathcal{M}_{m,n}(\mathbb{K}) \) associée à \( f \) est définie par :

\[
f(\vec{e}_j) = \sum_{i=1}^{m} a_{ij} \vec{f}_i, \quad \text{pour } j = 1, \dots, n
\]

Les coefficients \( a_{ij} \) constituent les éléments de la matrice \( A \). Ainsi, pour tout vecteur \( \vec{v} \in V \), exprimé dans la base \( \{ \vec{e}_j \} \), l'image \( f(\vec{v}) \) est donnée par :

\[
f(\vec{v}) = A \vec{v}
\]

### 4.2 Exemple

Soit \( f : \mathbb{R}^2 \rightarrow \mathbb{R}^2 \) définie par :

\[
f(x, y) = (3x + 2y, x - y)
\]

- **Base canonique** de \( \mathbb{R}^2 \) :

  \[
  \vec{e}_1 = (1, 0), \quad \vec{e}_2 = (0, 1)
  \]

- **Images des vecteurs de base** :

  \[
  f(\vec{e}_1) = f(1, 0) = (3, 1) = 3\vec{f}_1 + 1\vec{f}_2
  \]

  \[
  f(\vec{e}_2) = f(0, 1) = (2, -1) = 2\vec{f}_1 - 1\vec{f}_2
  \]

- **Matrice associée à \( f \) dans la base canonique** :

  \[
  A = \begin{pmatrix}
  3 & 2 \\
  1 & -1 \\
  \end{pmatrix}
  \]

Ainsi, pour tout \( \vec{v} = \begin{pmatrix} x \\ y \end{pmatrix} \), on a :

\[
f(\vec{v}) = A \vec{v} = \begin{pmatrix}
3 & 2 \\
1 & -1 \\
\end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}
\]

## 5. Composition et Inverse des Applications Linéaires

### 5.1 Composition

La **composition** de deux applications linéaires \( f : U \rightarrow V \) et \( g : V \rightarrow W \) est l'application linéaire \( h : U \rightarrow W \) définie par :

\[
h = g \circ f
\]

**Preuve de la linéarité** :

- Pour \( \vec{u}, \vec{v} \in U \) et \( \alpha \in \mathbb{K} \) :

  \[
  h(\vec{u} + \vec{v}) = g(f(\vec{u} + \vec{v})) = g(f(\vec{u}) + f(\vec{v})) = g(f(\vec{u})) + g(f(\vec{v})) = h(\vec{u}) + h(\vec{v})
  \]

  \[
  h(\alpha \vec{u}) = g(f(\alpha \vec{u})) = g(\alpha f(\vec{u})) = \alpha g(f(\vec{u})) = \alpha h(\vec{u})
  \]

### 5.2 Inverse d'une Application Linéaire

Une application linéaire \( f : V \rightarrow W \) est **bijective** si elle est à la fois injective (chaque élément de \( W \) a au plus un antécédent dans \( V \)) et surjective (tout élément de \( W \) est l'image d'au moins un élément de \( V \)).

Dans ce cas, l'application réciproque \( f^{-1} : W \rightarrow V \) est également linéaire.

**Propriétés** :

- Si \( f \) est bijective, alors \( \dim(V) = \dim(W) \).
- La matrice de \( f^{-1} \) est l'inverse de la matrice de \( f \).

## 6. Isomorphismes d'Espaces Vectoriels

Un **isomorphisme** est une application linéaire bijective entre deux espaces vectoriels \( V \) et \( W \). Deux espaces vectoriels sont dits **isomorphes** s'il existe un isomorphisme entre eux.

**Conséquences** :

- Les espaces vectoriels isomorphes ont la même dimension.
- Ils sont structurellement identiques du point de vue de l'algèbre linéaire.

### Exemple

- L'espace \( \mathbb{R}^n \) est isomorphe à tout espace vectoriel de dimension \( n \) sur \( \mathbb{R} \).

## 7. Applications en Mécanique et Robotique

Les applications linéaires sont omniprésentes en mécanique et en robotique, notamment pour :

- **Modéliser les transformations géométriques** : rotations, translations et homothéties peuvent être représentées par des matrices agissant sur des vecteurs de position.
- **Analyser les systèmes dynamiques** : les équations de mouvement linéaires peuvent être étudiées à l'aide d'applications linéaires.
- **Résoudre les équations différentielles linéaires** : la linéarité permet d'appliquer des méthodes analytiques et numériques efficaces.
- **Changer de base** : simplifier les calculs en choisissant des bases adaptées, par exemple les bases propres.

### Exemple : Transformation de Rotation

La rotation dans le plan de \( \theta \) radians autour de l'origine est une application linéaire \( R_\theta : \mathbb{R}^2 \rightarrow \mathbb{R}^2 \) définie par :

\[
R_\theta \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta \\
\end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}
\]

Cette matrice de rotation conserve les distances et les angles, ce qui est essentiel en mécanique pour décrire des mouvements rigides.

## 8. Conclusion

Les applications linéaires sont des outils puissants pour comprendre les relations entre les espaces vectoriels. Elles permettent de modéliser des transformations, de résoudre des systèmes d'équations, et de simplifier des problèmes complexes en les exprimant dans des bases appropriées.

En maîtrisant les concepts suivants :

- **Définition et propriétés des applications linéaires**.
- **Noyau et image**, qui fournissent des informations sur l'injectivité et la surjectivité.
- **Représentation matricielle**, reliant les applications linéaires aux matrices.
- **Composition et inverses**, pour combiner et inverser les transformations.
- **Isomorphismes**, qui identifient des espaces vectoriels équivalents en termes de structure.

vous serez bien préparés pour aborder des sujets plus avancés en algèbre linéaire, tels que la diagonalisation, les formes quadratiques et les valeurs propres, qui ont des applications profondes en mathématiques et en physique.
